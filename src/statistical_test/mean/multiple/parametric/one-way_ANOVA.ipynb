{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-way ANOVA (and normality / sphericity check)\n",
    "\n",
    "To use ANOVA, you need to make sure that the data fulfill these requirements:\n",
    "- Normality\n",
    "- Homogeneity of variances / SphericityTo use ANOVA, you need to make sure that the data fulfill these requirements:\n",
    "- Normality\n",
    "- Homogeneity of variances / Sphericity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '../../../../../data/statistical_test/one-way_ANOVA_ex_data.csv'\n",
    "ALPHA = 0.05\n",
    "NUM_OF_PARTICIPANTS = 8\n",
    "# OUTPUT_PATH = 'output/'\n",
    "# if not os.path.isdir(OUTPUT_PATH):\n",
    "    # os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(CSV_PATH, index_col=0)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = stats.shapiro(data['Standard'])\n",
    "\n",
    "print('p={:.5f}'.format(p))\n",
    "if p > ALPHA:\n",
    "    print('Normality check: passed')\n",
    "else:\n",
    "    print('Normality check: rejected')\n",
    "\n",
    "_, p = stats.shapiro(data['Prediction'])\n",
    "print('p={:.5f}'.format(p))\n",
    "if p > ALPHA:\n",
    "    print('Normality check: passed')\n",
    "else:\n",
    "    print('Normality check: rejected')\n",
    "\n",
    "_, p = stats.shapiro(data['Speech'])\n",
    "print('p={:.5f}'.format(p))\n",
    "if p > ALPHA:\n",
    "    print('Normality check: passed')\n",
    "else:\n",
    "    print('Normality check: rejected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneity of variances / Sphericity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = stats.bartlett(data['Standard'], data['Prediction'], data['Speech'])\n",
    "print('p={:.5f}'.format(p))\n",
    "if p > ALPHA:\n",
    "    print('Sphericity check: passed')\n",
    "else:\n",
    "    print('Sphericity check: rejected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = stats.f_oneway(data['Standard'], data['Prediction'], data['Speech'])\n",
    "print('ANOVA: p={:.5f}'.format(p))\n",
    "\n",
    "if p > ALPHA:\n",
    "    print('Same distributions')\n",
    "    # exit()\n",
    "else:\n",
    "    print('Different distributions. You can do a post-hoc test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple comparisons\n",
    "No significant difference is found on this data, thus no need to conduct a post-hoc test. \n",
    "\n",
    "But, as an example, Iâ€™ll show you a post-hoc test with this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey-HSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/TaigaU121/items/12c480f51a026ca9f333\n",
    "def tukey_hsd(ind, *args):\n",
    "    data_arr = np.hstack( args ) \n",
    "\n",
    "    ind_arr = np.array([])\n",
    "    for x in range(len(args)):\n",
    "        ind_arr = np.append(ind_arr, np.repeat(ind[x], len(args[x]))) \n",
    "    print(pairwise_tukeyhsd(data_arr,ind_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_hsd(['Standard', 'Prediction', 'Speech'], data['Standard'], data['Prediction'], data['Speech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test (with Bonferroni correction)\n",
    "t-test can be used for multiple comparisions, but p-value needs to be corrected to avoid multiplicity of statistical tests.\n",
    "\n",
    "i.e. if you done a statistical test with 95% confidence 3 times, the confidence of the results is 0.95 x 0.95 x 0.95 = 0.857375."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard vs Prediction\n",
    "_, p = stats.ttest_rel(data['Standard'], data['Prediction'])\n",
    "print('Standard vs Prediction: p={:.5f}'.format(p * 3))  # Bonferroni correction\n",
    "\n",
    "# Prediction vs Speech\n",
    "_, p = stats.ttest_rel(data['Prediction'], data['Speech'])\n",
    "print('Prediction vs Speech: p={:.5f}'.format(p * 3))  # Bonferroni correction\n",
    "\n",
    "# Speech vs Standard\n",
    "_, p = stats.ttest_rel(data['Speech'], data['Standard'])\n",
    "print('Speech vs Standard: p={:.5f}'.format(p * 3))  # Bonferroni correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "3 different data visualizations (Bar plot, Box plot, Violin plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot (average & standard error)\n",
    "pros: easy to compare multiple data (average)\n",
    "\n",
    "cons: less informative (average and standard error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "standard_mu = data['Standard'].mean()\n",
    "prediction_mu = data['Prediction'].mean()\n",
    "speech_mu = data['Speech'].mean()\n",
    "\n",
    "# Standard deviation\n",
    "standard_sd = data['Standard'].std()\n",
    "prediction_sd = data['Prediction'].std()\n",
    "speech_sd = data['Speech'].std()\n",
    "\n",
    "# Standard error\n",
    "standard_se = standard_sd / np.sqrt(NUM_OF_PARTICIPANTS)\n",
    "prediction_se = prediction_sd / np.sqrt(NUM_OF_PARTICIPANTS)\n",
    "speech_se = speech_sd / np.sqrt(NUM_OF_PARTICIPANTS)\n",
    "\n",
    "y = np.array([standard_mu, prediction_mu, speech_mu])\n",
    "e = np.array([standard_se, prediction_se, speech_se])\n",
    "\n",
    "x = np.array([\"Standard\", 'Prediction', 'Speech'])\n",
    "x_position = np.arange(len(x))\n",
    "error_bar_set = dict(lw=1, capthik=1, capsize=10)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.bar(x_position, y, yerr=e, tick_label=x, error_kw=error_bar_set, color=['salmon', 'palegreen', 'aqua'])\n",
    "ax.set_xlabel('Conditions', fontsize=14)\n",
    "ax.set_ylabel('Performance', fontsize=14)\n",
    "ax.set_ylim(0, 350)\n",
    "\n",
    "# plt.savefig(os.path.join(OUTPUT_PATH, 'ANOVA_bar.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot\n",
    "pros:\n",
    "more informative than bar plot\n",
    "\n",
    "cons:\n",
    "unable to understand the data distribution (box plot only show summary statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bar: min/max\n",
    "# box: 25/50(median)/75 percentile\n",
    "# circle: outlier (1.5 times bigger/smaller than box)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.boxplot([data['Standard'], data['Prediction'], data['Speech']], labels=['Standard', 'Prediction', 'Speech'])\n",
    "ax.set_xlabel('Conditions', fontsize=14)\n",
    "ax.set_ylabel('Performance', fontsize=14)\n",
    "ax.set_ylim(0, 370)\n",
    "\n",
    "# plt.savefig(os.path.join(OUTPUT_PATH, 'ANOVA_box.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plot\n",
    "pros: more informative than box plot (beacuse violin plot represents data distribution)\n",
    "\n",
    "cons:less popular (their meaning can be harder to grasp for many readers not familiar with the violin plot representation)### Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to box plot, but also represents kernel density estimation (estimated distribution of data)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.violinplot(data=[data['Standard'], data['Prediction'], data['Speech']], palette=['salmon', 'palegreen', 'aqua'])\n",
    "ax.set_xticklabels(['Standard', 'Prediction', 'Speech'])\n",
    "ax.set_xlabel('Conditions', fontsize=14)\n",
    "ax.set_ylabel('Performance', fontsize=14)\n",
    "ax.set_ylim(0, 400)\n",
    "\n",
    "# plt.savefig(os.path.join(OUTPUT_PATH, 'ANOVA_violin.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('ex_design_analysis': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d93d3809a412eeca67f3d81705e284a9fa16a5e112e379b94b99b867ad05122c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
